{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Procura de Problemas Éticos em Issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports necessários para o funcionamento:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install nltk\n",
    "%pip install ipywidgets\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fazendo a leitura dos dados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = pd.read_csv(\"path_to_csv\")\n",
    "comentarios = pd.read_csv(\"path_to_csv\")\n",
    "\n",
    "# Concatenando o Titulo e a Descrição das issues\n",
    "issues['Info'] = issues['TituloIssue'] + issues['DescricaoIssue']\n",
    "\n",
    "# Convertendo todos os tipos para String\n",
    "issues['Info'] = issues['Info'].astype(str).str.lower()\n",
    "comentarios['Comentario'] = comentarios['Comentario'].astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenizando os Comentarios, Titulo e Descrição das Issues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as StopWords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "def removerStopWords(palavras):\n",
    "    return [palavra for palavra in palavras if palavra not in stopWords and palavra.isalpha() or palavra in expressoes]\n",
    "\n",
    "# Criando um tokenizer que considera expressões\n",
    "expressoes = {'data governance', 'data protection','informed consent', 'lack of data', 'user data collection' 'business ethics','conflict of interest',\n",
    "            'human agency', 'intellectual property','regulatory approaches', 'self-conception','professional ethics', 'work ethics','common goods','individual differences',\n",
    "            'non-discrimination', 'non-maleficence','prevention of harm', 'quality of life', 'respect for human autonomy', 'retention and addiction', 'social justice',\n",
    "            'speech issues', 'technical robustness','computer abuse', 'malicious use'}\n",
    "\n",
    "expressaoRegular = r'\\b(?:' + '|'.join(map(re.escape,expressoes)) + r')\\b|\\w+'\n",
    "tokenizer = RegexpTokenizer(expressaoRegular)\n",
    "\n",
    "\n",
    "# Tokenize dos comentarios das issues\n",
    "comentariosToK = []\n",
    "for i in range (comentarios['Comentario'].size):\n",
    "    comentariosToK.append(removerStopWords(tokenizer.tokenize(comentarios.loc[i]['Comentario'])))\n",
    "\n",
    "# Tokenize do campo Info\n",
    "tituloDescricaoToK = []\n",
    "for k in range(issues['Info'].size):\n",
    "    tituloDescricaoToK.append(removerStopWords(tokenizer.tokenize(issues.loc[k]['Info'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Contando a ocorrência de problemas éticos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RSLPStemmer\n",
    "nltk.download('rslp')\n",
    "radicalizador = RSLPStemmer()\n",
    "\n",
    "\n",
    "# Definindo os EthicalIssues\n",
    "EthicalIssues = ['bias', 'data', 'encryption', 'monetization', 'openness', 'privacy', 'authorship', 'autonomy', 'beneficence', 'commerce', 'compliance', 'confidentiality',\n",
    "                 'context', 'dependability', 'fairness', 'oversight', 'responsibility', 'trust', 'trustworthiness', 'axiology', 'freedom', 'solidarity', 'utility',\n",
    "                 'care', 'competence', 'access', 'accessibility', 'dignity', 'diversity', 'equality', 'equity', 'humanity', 'inclusiveness', 'inequality', 'justice', \n",
    "                 'participation', 'plurality', 'sustainability', 'unemployment', 'welfare', 'accountability', 'accuracy', 'anonymity', 'comprehensibility', 'consistency',\n",
    "                 'contestability', 'explainability', 'explicability', 'integrity', 'interpretability', 'liability', 'reliability', 'safety', 'security', 'traceability', 'transparency',\n",
    "                 'usability', 'data governance', 'data protection', 'informed consent', 'lack of data', 'user data collection', 'business ethics', 'conflict of interest', \n",
    "                 'human agency', 'intellectual property', 'regulatory approaches', 'professional ethics', 'individual differences', 'self-conception', 'work ethics', \n",
    "                 'common goods', 'non-discrimination', 'non-maleficence', 'prevention of harm', 'quality of life', 'respect for human autonomy', 'retention and addiction', \n",
    "                 'social justice', 'speech issues', 'technical robustness', 'computer abuse', 'malicious use']\n",
    "\n",
    "# Criando o DataFrame que guardará as ocorrências dos comentários\n",
    "ocorrenciasComents = pd.DataFrame()\n",
    "linhaInicial = 0 * len(EthicalIssues)\n",
    "palavrasAntes = \"\" * len(EthicalIssues)\n",
    "palavrasDepois = \"\" * len(EthicalIssues)\n",
    "\n",
    "ocorrenciasComents['EthicalIssues'] = EthicalIssues\n",
    "ocorrenciasComents['Ocorrencias'] = linhaInicial\n",
    "ocorrenciasComents[\"PalavrasAntes\"] = palavrasAntes\n",
    "ocorrenciasComents[\"PalavrasDepois\"] = palavrasDepois\n",
    "ocorrenciasComents = ocorrenciasComents.set_index('EthicalIssues')\n",
    "ocorrenciasComents\n",
    "\n",
    "# Criando o DataFrame que guardará as ocorrências do título e descrição\n",
    "ocorrenciasTituloDescricao = pd.DataFrame()\n",
    "linhaInicial = 0 * len(EthicalIssues)\n",
    "palavrasAntes = \"\" * len(EthicalIssues)\n",
    "palavrasDepois = \"\" * len(EthicalIssues)\n",
    "\n",
    "ocorrenciasTituloDescricao['EthicalIssues'] = EthicalIssues\n",
    "ocorrenciasTituloDescricao['Ocorrencias'] = linhaInicial\n",
    "ocorrenciasTituloDescricao[\"PalavrasAntes\"] = palavrasAntes\n",
    "ocorrenciasTituloDescricao[\"PalavrasDepois\"] = palavrasDepois\n",
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.set_index('EthicalIssues')\n",
    "\n",
    "EthicalIssues = [radicalizador.stem(palavra) for palavra in EthicalIssues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(comentariosToK)): \n",
    "    for j in range(len(comentariosToK[i])):\n",
    "        \n",
    "        if(radicalizador.stem(comentariosToK[i][j]) in EthicalIssues): # Acho que aqui seria o melhor momento para verificar (comentariosToK[i][j] seria radicalizada apenas para verificação)\n",
    "            \n",
    "            try:\n",
    "                ocorrenciasComents.loc[comentariosToK[i][j], 'Ocorrencias'] += 1\n",
    "            except:\n",
    "                ocorrenciasComents.loc[comentariosToK[i][j]] = [1, \"\", \"\"]\n",
    "                \n",
    "            \n",
    "            \n",
    "            if((j - 1) >= 0):\n",
    "                if(ocorrenciasComents.loc[comentariosToK[i][j],'PalavrasAntes'] == ''):\n",
    "                    ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasAntes'] = comentariosToK[i][j - 1]\n",
    "                else:\n",
    "                    ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasAntes'] += ('\\n' + comentariosToK[i][j - 1])\n",
    "            if((j + 1) <= (len(comentariosToK[i]) - 1)):\n",
    "                if(ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasDepois'] == ''):\n",
    "                    ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasDepois'] = comentariosToK[i][j + 1]\n",
    "                else:\n",
    "                    ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasDepois'] += ('\\n' + comentariosToK[i][j + 1])\n",
    "\n",
    "\n",
    "for i in range(len(tituloDescricaoToK)):\n",
    "    for j in range(len(tituloDescricaoToK[i])):\n",
    "        \n",
    "        if(radicalizador.stem(tituloDescricaoToK[i][j]) in EthicalIssues): # Acho que aqui seria o melhor momento para verificar (tituloDescricaoToK[i][j] seria radicalizada apenas para verificação)\n",
    "            \n",
    "            try:\n",
    "                ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'Ocorrencias'] += 1\n",
    "            except:\n",
    "                ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j]] = [1, \"\", \"\"]\n",
    "            \n",
    "            if((j - 1) >= 0):\n",
    "                if(ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j],'PalavrasAntes'] == ''):\n",
    "                    ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasAntes'] = tituloDescricaoToK[i][j - 1]\n",
    "                else:\n",
    "                    ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasAntes'] += ('\\n' + tituloDescricaoToK[i][j - 1])\n",
    "            if((j + 1) <= (len(tituloDescricaoToK[i]) - 1)):\n",
    "                if(ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasDepois'] == ''):\n",
    "                    ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasDepois'] = tituloDescricaoToK[i][j + 1]\n",
    "                else:\n",
    "                    ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasDepois'] += ('\\n' + tituloDescricaoToK[i][j + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deixando o dataframe no formato correto:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.reset_index()\n",
    "ocorrenciasComents = ocorrenciasComents.reset_index()\n",
    "\n",
    "ocorrenciasTituloDescricao['PalavrasAntes'] = ocorrenciasTituloDescricao['PalavrasAntes'].str.split('\\n')\n",
    "ocorrenciasTituloDescricao['PalavrasDepois'] = ocorrenciasTituloDescricao['PalavrasDepois'].str.split('\\n')\n",
    "\n",
    "ocorrenciasComents['PalavrasAntes'] = ocorrenciasComents['PalavrasAntes'].str.split('\\n')\n",
    "ocorrenciasComents['PalavrasDepois'] = ocorrenciasComents['PalavrasDepois'].str.split('\\n')\n",
    "\n",
    "ocorrenciasComents = ocorrenciasComents[ocorrenciasComents['Ocorrencias'] > 0]\n",
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao[ocorrenciasTituloDescricao['Ocorrencias'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Criando uma tabela expansivel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar a tabela com linhas expansíveis e contagem de palavras\n",
    "def criarTabelaExpansivel(df):\n",
    "    displayWidgets = []\n",
    "    \n",
    "    for _, linha in df.iterrows():\n",
    "        # Conta as palavras em 'palavrasAntes' e 'palavrasDepois'\n",
    "        antes_counts = Counter(linha['PalavrasAntes']).most_common()  # Ordena por contagem (decrescente)\n",
    "        depois_counts = Counter(linha['PalavrasDepois']).most_common()  # Ordena por contagem (decrescente)\n",
    "        \n",
    "        # Cria uma linha com os dados principais\n",
    "        linha_widget = widgets.HBox([\n",
    "            widgets.Label(value=str(linha[\"EthicalIssues\"]), layout=widgets.Layout(width=\"120px\")),\n",
    "            widgets.Label(value=str(linha[\"Ocorrencias\"]), layout=widgets.Layout(width=\"60px\")),\n",
    "            widgets.Label(value=\"Clique para expandir\", layout=widgets.Layout(width=\"200px\"))\n",
    "        ])\n",
    "        \n",
    "        # Cria o conteúdo expansível com `palavrasAntes` e `palavrasDepois` e suas contagens\n",
    "        widgetDetalhes = widgets.VBox([\n",
    "            widgets.Label(value=f\"Palavras Antes: {', '.join([f'{word} ({count})' for word, count in antes_counts])}\"),\n",
    "            widgets.Label(value=f\"Palavras Depois: {', '.join([f'{word} ({count})' for word, count in depois_counts])}\")\n",
    "        ])\n",
    "        \n",
    "        # Torna o conteúdo expansível\n",
    "        expansao = widgets.Accordion(children=[widgetDetalhes])\n",
    "        expansao.set_title(0, f\"Detalhes de '{linha['EthicalIssues']}'\")\n",
    "        \n",
    "        # Agrupa a linha principal e o conteúdo expansível\n",
    "        linha_box = widgets.VBox([linha_widget, expansao])\n",
    "        displayWidgets.append(linha_box)\n",
    "    \n",
    "    # Exibe a tabela com todas as linhas e detalhes\n",
    "    display(widgets.VBox(displayWidgets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exibindo os resultados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a tabela expansível\n",
    "criarTabelaExpansivel(ocorrenciasComents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a tabela expansível\n",
    "criarTabelaExpansivel(ocorrenciasTituloDescricao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exportando as Tabelas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportando como html\n",
    "\n",
    "def exportar_para_html(df, filepath):\n",
    "    html = \"\"\"<html>\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <style>\n",
    "            table {width: 100%%; border-collapse: collapse;}\n",
    "            th, td {border: 1px solid black; padding: 8px; text-align: left;}\n",
    "            th {background-color: #f2f2f2;}\n",
    "            .detalhes {display: none;}\n",
    "        </style>\n",
    "        <script>\n",
    "            function toggleDetalhes(id) {\n",
    "                var elemento = document.getElementById(id);\n",
    "                elemento.style.display = (elemento.style.display === \"none\") ? \"block\" : \"none\";\n",
    "            }\n",
    "        </script>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h2>Tabela Expansível</h2>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>Ethical Issues</th>\n",
    "                <th>Ocorrências</th>\n",
    "                <th>Detalhes</th>\n",
    "            </tr>\n",
    "    \"\"\"\n",
    "\n",
    "    for i, (_, linha) in enumerate(df.iterrows()):\n",
    "        antes_counts = Counter(linha[\"PalavrasAntes\"]).most_common()\n",
    "        depois_counts = Counter(linha[\"PalavrasDepois\"]).most_common()\n",
    "\n",
    "        detalhes = f\"\"\"<p><strong>Palavras Antes:</strong> {', '.join([f'{word} ({count})' for word, count in antes_counts])}</p>\n",
    "                       <p><strong>Palavras Depois:</strong> {', '.join([f'{word} ({count})' for word, count in depois_counts])}</p>\"\"\"\n",
    "\n",
    "        html += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{linha[\"EthicalIssues\"]}</td>\n",
    "                <td>{linha[\"Ocorrencias\"]}</td>\n",
    "                <td><button onclick=\"toggleDetalhes('detalhes{i}')\">Expandir</button></td>\n",
    "            </tr>\n",
    "            <tr id=\"detalhes{i}\" class=\"detalhes\">\n",
    "                <td colspan=\"3\">{detalhes}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "\n",
    "    html += \"</table></body></html>\"\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportar_para_html(ocorrenciasComents, \"path_to_html\")\n",
    "exportar_para_html(ocorrenciasTituloDescricao, \"path_to_html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
