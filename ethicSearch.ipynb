{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Procura de Problemas Éticos em Issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports necessários para o funcionamento:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install nltk\n",
    "%pip install ipywidgets\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fazendo a leitura dos dados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = pd.read_csv(\"path_to_csv\")\n",
    "comentarios = pd.read_csv(\"path_to_csv\")\n",
    "\n",
    "# Concatenando o Titulo e a Descrição das issues\n",
    "issues['Info'] = issues['TituloIssue'] + issues['DescricaoIssue']\n",
    "\n",
    "# Convertendo todos os tipos para Strings minusculas\n",
    "issues['Info'] = issues['Info'].astype(str).str.lower()\n",
    "comentarios['Comentario'] = comentarios['Comentario'].astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenizando os Comentarios, Titulo e Descrição das Issues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as StopWords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "# Função que remove as stopwords\n",
    "def removerStopWords(palavras):\n",
    "    return [palavra for palavra in palavras if palavra not in stopWords and palavra.isalpha() or palavra in expressoes]\n",
    "\n",
    "# Criando um tokenizer que considera expressões\n",
    "expressoes = {'data governance', 'data protection','informed consent', 'lack of data', 'user data collection' 'business ethics','conflict of interest',\n",
    "            'human agency', 'intellectual property','regulatory approaches', 'self-conception','professional ethics', 'work ethics','common goods','individual differences',\n",
    "            'non-discrimination', 'non-maleficence','prevention of harm', 'quality of life', 'respect for human autonomy', 'retention and addiction', 'social justice',\n",
    "            'speech issues', 'technical robustness','computer abuse', 'malicious use'}\n",
    "\n",
    "expressaoRegular = r'\\b(?:' + '|'.join(map(re.escape,expressoes)) + r')\\b|\\w+'\n",
    "tokenizer = RegexpTokenizer(expressaoRegular)\n",
    "\n",
    "\n",
    "# Tokenize dos comentarios das issues\n",
    "comentariosToK = []\n",
    "for i in range (comentarios['Comentario'].size):\n",
    "    comentariosToK.append(removerStopWords(tokenizer.tokenize(comentarios.loc[i]['Comentario'])))\n",
    "\n",
    "# Tokenize do campo Info\n",
    "tituloDescricaoToK = []\n",
    "for k in range(issues['Info'].size):\n",
    "    tituloDescricaoToK.append(removerStopWords(tokenizer.tokenize(issues.loc[k]['Info'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preparando o Dataframe com os termos relacionados à ética:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo os EthicalIssues\n",
    "EthicalIssuesOtavio = ['bias', 'data', 'encryption', 'monetization', 'openness', 'privacy', 'authorship', 'autonomy', 'beneficence', 'commerce', 'compliance', 'confidentiality',\n",
    "                 'context', 'dependability', 'fairness', 'oversight', 'responsibility', 'trust', 'trustworthiness', 'axiology', 'freedom', 'solidarity', 'utility',\n",
    "                 'care', 'competence', 'access', 'accessibility', 'dignity', 'diversity', 'equality', 'equity', 'humanity', 'inclusiveness', 'inequality', 'justice', \n",
    "                 'participation', 'plurality', 'sustainability', 'unemployment', 'welfare', 'accountability', 'accuracy', 'anonymity', 'comprehensibility', 'consistency',\n",
    "                 'contestability', 'explainability', 'explicability', 'integrity', 'interpretability', 'liability', 'reliability', 'safety', 'security', 'traceability', 'transparency',\n",
    "                 'usability', 'data governance', 'data protection', 'informed consent', 'lack of data', 'user data collection', 'business ethics', 'conflict of interest', \n",
    "                 'human agency', 'intellectual property', 'regulatory approaches', 'professional ethics', 'individual differences', 'self-conception', 'work ethics', \n",
    "                 'common goods', 'non-discrimination', 'non-maleficence', 'prevention of harm', 'quality of life', 'respect for human autonomy', 'retention and addiction', \n",
    "                 'social justice', 'speech issues', 'technical robustness', 'computer abuse', 'malicious use']\n",
    "\n",
    "EthicalIssuesBase = ['fairness', 'bias', 'safety', 'harmful content', 'toxicity', 'hallucinations', 'privacy', 'data protection', 'interaction risks', 'security', 'robustness', \n",
    "                 'education', 'learning', 'aligment', 'cybercrime', 'governance', 'regulation', 'labor displacement', 'economic impact', 'transparency', 'explainability', \n",
    "                 'evaluation', 'auditing', 'sustainability', 'art', 'creativity', 'copyright', 'autorship', 'writing', 'research', 'miscellaneous']\n",
    "\n",
    "EthicalIssuesWordnet = ['fairness', 'bias', 'fairly', 'equity', 'preconception', 'safety', 'safe', 'harmful content', 'toxicity', 'toxic', 'harm', 'risk', 'authoriativeness',\n",
    "                        'sensitivity', 'misinformation', 'inaccuracies', 'privacy', 'data protection', 'privateness', 'secrecy', 'interaction risks', 'overreliance',\n",
    "                        'manipulation', 'unethical actions', 'dependency', 'lack of empaty', 'security', 'robustness', 'protection', 'validity', 'hardiness', 'cybercrime', 'attack',\n",
    "                        'fraud', 'governance', 'regulation', 'administration', 'regularisation', 'regulating', 'economic impact', 'effect', 'economical', 'transparency',\n",
    "                        'explainability', 'transparence', 'transparentness', 'evaluation', 'auditing', 'rating', 'valuating', 'audit', 'inspect', 'sustainability', 'renewable energy',\n",
    "                        'copyright', 'authorship', 'plagiarism', 'accountability', 'responsibly', 'trustworthiness', 'moral views']\n",
    "\n",
    "EthicalIssues = list(set(EthicalIssuesWordnet + EthicalIssuesOtavio))\n",
    "\n",
    "\n",
    "# Criando o DataFrame que guardará as ocorrências dos comentários\n",
    "ocorrenciasComents = pd.DataFrame()\n",
    "ocorrenciasComents['EthicalIssues'] = EthicalIssues\n",
    "ocorrenciasComents['Ocorrencias'] = 0\n",
    "ocorrenciasComents['PalavrasAntes'] = \"\"\n",
    "ocorrenciasComents['PalavrasDepois'] = \"\"\n",
    "ocorrenciasComents = ocorrenciasComents.set_index('EthicalIssues')\n",
    "\n",
    "# Criando o DataFrame que guardará as ocorrências do título e descrição\n",
    "ocorrenciasTituloDescricao = pd.DataFrame()\n",
    "ocorrenciasTituloDescricao['EthicalIssues'] = EthicalIssues\n",
    "ocorrenciasTituloDescricao['Ocorrencias'] = 0\n",
    "ocorrenciasTituloDescricao['PalavrasAntes'] = \"\"\n",
    "ocorrenciasTituloDescricao['PalavrasDepois'] = \"\"\n",
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.set_index('EthicalIssues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Contando a ocorrência dos termos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que faz a contagem das ocorrências dos termos e conta as palavras antes e depois\n",
    "def contaOcorrencias(tokens, dfOcorrencias):\n",
    "    for listaTokens in tokens:\n",
    "        for index, token in enumerate(listaTokens):\n",
    "            if token in dfOcorrencias.index:\n",
    "                \n",
    "                # Adicionando uma ocorrência do token\n",
    "                dfOcorrencias.loc[token, 'Ocorrencias'] += 1\n",
    "                \n",
    "                if (index > 0):\n",
    "                    # Adicionando a palavra anterior se existir\n",
    "                    if (dfOcorrencias.loc[token, 'PalavrasAntes'] == \"\"):\n",
    "                        dfOcorrencias.loc[token, 'PalavrasAntes'] = listaTokens[index - 1]\n",
    "                    else:\n",
    "                       dfOcorrencias.loc[token, 'PalavrasAntes']  += (\"\\n\" + listaTokens[index - 1])\n",
    "                    \n",
    "                if (index < len(listaTokens) - 1):\n",
    "                    # Adicionando a palavra depois se existir\n",
    "                    if (dfOcorrencias.loc[token, 'PalavrasDepois'] == \"\"):\n",
    "                        dfOcorrencias.loc[token, 'PalavrasDepois'] = listaTokens[index + 1]\n",
    "                    else:\n",
    "                       dfOcorrencias.loc[token, 'PalavrasDepois']  += (\"\\n\" + listaTokens[index + 1])\n",
    "\n",
    "contaOcorrencias(comentariosToK, ocorrenciasComents)\n",
    "contaOcorrencias(tituloDescricaoToK, ocorrenciasTituloDescricao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deixando o dataframe no formato correto:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.reset_index()\n",
    "ocorrenciasComents = ocorrenciasComents.reset_index()\n",
    "\n",
    "ocorrenciasTituloDescricao['PalavrasAntes'] = ocorrenciasTituloDescricao['PalavrasAntes'].str.split('\\n')\n",
    "ocorrenciasTituloDescricao['PalavrasDepois'] = ocorrenciasTituloDescricao['PalavrasDepois'].str.split('\\n')\n",
    "\n",
    "ocorrenciasComents['PalavrasAntes'] = ocorrenciasComents['PalavrasAntes'].str.split('\\n')\n",
    "ocorrenciasComents['PalavrasDepois'] = ocorrenciasComents['PalavrasDepois'].str.split('\\n')\n",
    "\n",
    "ocorrenciasComents = ocorrenciasComents[ocorrenciasComents['Ocorrencias'] > 0]\n",
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao[ocorrenciasTituloDescricao['Ocorrencias'] > 0]\n",
    "\n",
    "ocorrenciasComents = ocorrenciasComents.sort_values(by='Ocorrencias', ascending=False)\n",
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.sort_values(by='Ocorrencias', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Criando uma tabela expansivel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar a tabela com linhas expansíveis e contagem de palavras\n",
    "def criarTabelaExpansivel(df):\n",
    "    displayWidgets = []\n",
    "    \n",
    "    for _, linha in df.iterrows():\n",
    "        # Conta as palavras em 'palavrasAntes' e 'palavrasDepois'\n",
    "        antes_counts = Counter(linha['PalavrasAntes']).most_common()  # Ordena por contagem (decrescente)\n",
    "        depois_counts = Counter(linha['PalavrasDepois']).most_common()  # Ordena por contagem (decrescente)\n",
    "        \n",
    "        # Cria uma linha com os dados principais\n",
    "        linha_widget = widgets.HBox([\n",
    "            widgets.Label(value=str(linha[\"EthicalIssues\"]), layout=widgets.Layout(width=\"120px\")),\n",
    "            widgets.Label(value=str(linha[\"Ocorrencias\"]), layout=widgets.Layout(width=\"60px\")),\n",
    "            widgets.Label(value=\"Clique para expandir\", layout=widgets.Layout(width=\"200px\"))\n",
    "        ])\n",
    "        \n",
    "        # Cria o conteúdo expansível com `palavrasAntes` e `palavrasDepois` e suas contagens\n",
    "        widgetDetalhes = widgets.VBox([\n",
    "            widgets.Label(value=f\"Palavras Antes: {', '.join([f'{word} ({count})' for word, count in antes_counts])}\"),\n",
    "            widgets.Label(value=f\"Palavras Depois: {', '.join([f'{word} ({count})' for word, count in depois_counts])}\")\n",
    "        ])\n",
    "        \n",
    "        # Torna o conteúdo expansível\n",
    "        expansao = widgets.Accordion(children=[widgetDetalhes])\n",
    "        expansao.set_title(0, f\"Detalhes de '{linha['EthicalIssues']}'\")\n",
    "        \n",
    "        # Agrupa a linha principal e o conteúdo expansível\n",
    "        linha_box = widgets.VBox([linha_widget, expansao])\n",
    "        displayWidgets.append(linha_box)\n",
    "    \n",
    "    # Exibe a tabela com todas as linhas e detalhes\n",
    "    display(widgets.VBox(displayWidgets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exibindo os resultados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a tabela expansível\n",
    "criarTabelaExpansivel(ocorrenciasComents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a tabela expansível\n",
    "criarTabelaExpansivel(ocorrenciasTituloDescricao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exportando as Tabelas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando a tabela expansível como um arquivo html\n",
    "\n",
    "def exportar_para_html(df, filepath):\n",
    "    html = \"\"\"<html>\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <style>\n",
    "            table {width: 100%%; border-collapse: collapse;}\n",
    "            th, td {border: 1px solid black; padding: 8px; text-align: left;}\n",
    "            th {background-color: #f2f2f2;}\n",
    "            .detalhes {display: none;}\n",
    "        </style>\n",
    "        <script>\n",
    "            function toggleDetalhes(id) {\n",
    "                var elemento = document.getElementById(id);\n",
    "                elemento.style.display = (elemento.style.display === \"none\") ? \"block\" : \"none\";\n",
    "            }\n",
    "        </script>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h2>Tabela Expansível</h2>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>Ethical Issues</th>\n",
    "                <th>Ocorrências</th>\n",
    "                <th>Detalhes</th>\n",
    "            </tr>\n",
    "    \"\"\"\n",
    "\n",
    "    for i, (_, linha) in enumerate(df.iterrows()):\n",
    "        antes_counts = Counter(linha[\"PalavrasAntes\"]).most_common()\n",
    "        depois_counts = Counter(linha[\"PalavrasDepois\"]).most_common()\n",
    "\n",
    "        detalhes = f\"\"\"<p><strong>Palavras Antes:</strong> {', '.join([f'{word} ({count})' for word, count in antes_counts])}</p>\n",
    "                       <p><strong>Palavras Depois:</strong> {', '.join([f'{word} ({count})' for word, count in depois_counts])}</p>\"\"\"\n",
    "\n",
    "        html += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{linha[\"EthicalIssues\"]}</td>\n",
    "                <td>{linha[\"Ocorrencias\"]}</td>\n",
    "                <td><button onclick=\"toggleDetalhes('detalhes{i}')\">Expandir</button></td>\n",
    "            </tr>\n",
    "            <tr id=\"detalhes{i}\" class=\"detalhes\">\n",
    "                <td colspan=\"3\">{detalhes}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "\n",
    "    html += \"</table></body></html>\"\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportar_para_html(ocorrenciasComents, \"path_to_html\")\n",
    "exportar_para_html(ocorrenciasTituloDescricao, \"path_to_html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
