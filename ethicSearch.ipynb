{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Procura de Problemas Éticos em Issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports necessários para o funcionamento:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install nltk\n",
    "%pip install ipywidgets\n",
    "%pip install seaborn\n",
    "%pip install matplotlib\n",
    "%pip install networkx\n",
    "%pip install plotly\n",
    "%pip install wordcloud\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fazendo a leitura dos dados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = pd.read_csv(\"out/llama-issues-3.csv\")\n",
    "comentarios = pd.read_csv(\"out/llama-comentarios-3.csv\")\n",
    "\n",
    "# Concatenando o Titulo e a Descrição das issues\n",
    "issues['Info'] = issues['TituloIssue'] + issues['DescricaoIssue']\n",
    "\n",
    "# Convertendo todos os tipos para Strings minusculas\n",
    "issues['Info'] = issues['Info'].astype(str).str.lower()\n",
    "comentarios['Comentario'] = comentarios['Comentario'].astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenizando os Comentarios, Titulo e Descrição das Issues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as StopWords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "# Função que remove as stopwords\n",
    "def removerStopWords(palavras):\n",
    "    return [palavra for palavra in palavras if palavra not in stopWords and palavra.isalpha() or palavra in expressoes]\n",
    "\n",
    "# Criando um tokenizer que considera expressões\n",
    "expressoes = {'data governance', 'data protection', 'informed consent', 'lack of data', 'user data collection', 'conflict of interest', 'human agency', 'intellectual property',\n",
    "              'regulatory approaches', 'professional ethics', 'work ethics', 'common goods', 'individual differences', 'prevention of harm', 'quality of life',\n",
    "              'respect for human autonomy', 'retention and addiction', 'social justice', 'speech issues', 'technical robustness', 'computer abuse', 'malicious use', 'context of use',\n",
    "              'self respect', 'harmful content', 'interaction risks', 'labor displacement', 'economic impact', 'unethical actions', 'lack of empaty', 'renewable energy', 'moral views'}\n",
    "\n",
    "expressaoRegular = r'\\b(?:' + '|'.join(map(re.escape,expressoes)) + r')\\b|\\w+'\n",
    "tokenizer = RegexpTokenizer(expressaoRegular)\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize dos comentarios das issues\n",
    "comentariosToK = []\n",
    "for i in range (comentarios['Comentario'].size):\n",
    "    comentariosToK.append(removerStopWords(tokenizer.tokenize(comentarios.loc[i]['Comentario'])))\n",
    "\n",
    "# Tokenize do campo Info\n",
    "tituloDescricaoToK = []\n",
    "for k in range(issues['Info'].size):\n",
    "    tituloDescricaoToK.append(removerStopWords(tokenizer.tokenize(issues.loc[k]['Info'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preparando o Dataframe com os termos relacionados à ética:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo os EthicalIssues\n",
    "\n",
    "def toLower(palavras):\n",
    "    return [palavra.lower() for palavra in palavras]\n",
    "\n",
    "\n",
    "TaxonomiaOtavio = ['Bias', 'Data Governance', 'Data Protection', 'Encryption', 'Informed Consent', 'Lack of Data', 'Monetization', 'Openness', 'Privacy', 'User Data Collection'\n",
    "                   'Authorship', 'Autonomy', 'Beneficence', 'Business', 'Ethics', 'Commerce', 'Compliance', 'Confidentiality', 'Conflict of Interest', 'Context', 'Dependability'\n",
    "                   'Fairness', 'Human Agency', 'Intellectual Property', 'Oversight', 'Regulatory Approaches', 'Responsibility', 'Trust', 'Trustworthiness', 'Axiology', 'Freedom'\n",
    "                   'Self-Conception', 'Solidarity', 'Utility', 'Care', 'Competence', 'Professional Ethics', 'Work Ethics', 'Access', 'Accessibility', 'Common Goods', 'Dignity',\n",
    "                   'Diversity', 'Equality', 'Equity', 'Humanity', 'Inclusiveness', 'Individual Differences', 'Inequality', 'Justice', 'Non-Discrimination', 'Non-Maleficence',\n",
    "                   'Participation', 'Plurality', 'Prevention of Harm', 'Quality of Life', 'Respect for Human Autonomy', 'Retention and Addiction', 'Social Justice', 'Sustainability',\n",
    "                   'Unemployment', 'Welfare', 'Accountability', 'Accuracy', 'Anonymity', 'Comprehensibility', 'Consistency', 'Contestability', 'Explainability', 'Explicability',\n",
    "                   'Integrity', 'Interpretability', 'Liability', 'Reliability', 'Safety', 'Security', 'Speech Issues', 'Technical Robustness', 'Traceability', 'Transparency',\n",
    "                   'Usability', 'Computer Abuse', 'Malicious Use']\n",
    "TaxonomiaOtavio = toLower(TaxonomiaOtavio)\n",
    "\n",
    "OtavioThesaurus = ['preconception', 'prejudice', 'encoding', 'receptiveness', 'receptivity', 'privateness', 'secrecy', 'self-sufficiency', 'morality', 'morals', 'commercialism',\n",
    "                   'conformation', 'conformity', 'context of use', 'dependableness', 'reliability', 'reliableness', 'equity', 'supervising', 'supervision', 'responsibleness',\n",
    "                   'reliance', 'trustfulness', 'trustingness', 'confidence', 'trustiness', 'usefulness', 'attention', 'caution', 'precaution', 'concern', 'competency', 'availability',\n",
    "                   'availableness', 'self respect', 'diverseness', 'variety', 'equivalence', 'fairness', 'humanness', 'justness', 'engagement', 'wellbeing', 'answerability',\n",
    "                   'namelessness', 'understandability', 'consistence', 'reliableness', 'safe', 'protection', 'transparence', 'transparentness', 'usableness', 'useableness']\n",
    "OtavioThesaurus = toLower(OtavioThesaurus)\n",
    "\n",
    "TaxonomiaArtigo = ['Fairness', 'Bias', 'Safety', 'Harmful content', 'Toxicity', 'Hallucinations', 'Privacy', 'Data protection', 'Interaction risks', 'Security', 'Robustness',\n",
    "                   'Cybercrime', 'Governance', 'Regulation', 'Labor displacement', 'Economic impact', 'Transparency', 'Explainability', 'Evaluation', 'Auditing', 'Sustainability', \n",
    "                   'Copyright', 'Authorship', 'Miscellaneous']\n",
    "TaxonomiaArtigo = toLower(TaxonomiaArtigo)\n",
    "\n",
    "ArtigoThesaurus = ['fairly', 'equity', 'preconception', 'safe', 'toxic', 'harm', 'risk', 'authoritativeness', 'sensitivity', 'misinformation', 'inaccuracies', 'privateness', 'secrecy',\n",
    "                   'overreliance', 'manipulation', 'unethical actions', 'dependency', 'lack of empaty', 'protection', 'validity', 'hardiness', 'attack', 'fraud', 'administration',\n",
    "                   'regularisation', 'regulating', 'effect', 'economical', 'transparence', 'transparentness', 'rating', 'valuation', 'audit', 'inspect', 'renewable energy',\n",
    "                   'plagiarism', 'Accountability', 'responsibly', 'trustworthiness', 'moral views']\n",
    "ArtigoThesaurus = toLower(ArtigoThesaurus)\n",
    "\n",
    "\n",
    "#EthicalIssues = TaxonomiaArtigo\n",
    "\n",
    "EthicalIssues = list(set(TaxonomiaArtigo + ArtigoThesaurus))\n",
    "\n",
    "# Criando o DataFrame que guardará as ocorrências dos comentários\n",
    "ocorrenciasComents = pd.DataFrame()\n",
    "ocorrenciasComents['EthicalIssues'] = EthicalIssues\n",
    "ocorrenciasComents['Ocorrencias'] = 0\n",
    "ocorrenciasComents['PalavrasAntes'] = \"\"\n",
    "ocorrenciasComents['PalavrasDepois'] = \"\"\n",
    "ocorrenciasComents = ocorrenciasComents.set_index('EthicalIssues')\n",
    "\n",
    "# Criando o DataFrame que guardará as ocorrências do título e descrição\n",
    "ocorrenciasTituloDescricao = pd.DataFrame()\n",
    "ocorrenciasTituloDescricao['EthicalIssues'] = EthicalIssues\n",
    "ocorrenciasTituloDescricao['Ocorrencias'] = 0\n",
    "ocorrenciasTituloDescricao['PalavrasAntes'] = \"\"\n",
    "ocorrenciasTituloDescricao['PalavrasDepois'] = \"\"\n",
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.set_index('EthicalIssues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Contando a ocorrência dos termos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que faz a contagem das ocorrências dos termos e conta as palavras antes e depois\n",
    "def contaOcorrencias(tokens, dfOcorrencias):\n",
    "    for listaTokens in tokens:\n",
    "        for index, token in enumerate(listaTokens):\n",
    "            if token in dfOcorrencias.index:\n",
    "                \n",
    "                # Adicionando uma ocorrência do token\n",
    "                dfOcorrencias.loc[token, 'Ocorrencias'] += 1\n",
    "                \n",
    "                if (index > 0):\n",
    "                    # Adicionando a palavra anterior se existir\n",
    "                    if (dfOcorrencias.loc[token, 'PalavrasAntes'] == \"\"):\n",
    "                        dfOcorrencias.loc[token, 'PalavrasAntes'] = listaTokens[index - 1]\n",
    "                    else:\n",
    "                       dfOcorrencias.loc[token, 'PalavrasAntes']  += (\"\\n\" + listaTokens[index - 1])\n",
    "                    \n",
    "                if (index < len(listaTokens) - 1):\n",
    "                    # Adicionando a palavra depois se existir\n",
    "                    if (dfOcorrencias.loc[token, 'PalavrasDepois'] == \"\"):\n",
    "                        dfOcorrencias.loc[token, 'PalavrasDepois'] = listaTokens[index + 1]\n",
    "                    else:\n",
    "                       dfOcorrencias.loc[token, 'PalavrasDepois']  += (\"\\n\" + listaTokens[index + 1])\n",
    "\n",
    "contaOcorrencias(comentariosToK, ocorrenciasComents)\n",
    "contaOcorrencias(tituloDescricaoToK, ocorrenciasTituloDescricao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deixando o dataframe no formato correto:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.reset_index()\n",
    "ocorrenciasComents = ocorrenciasComents.reset_index()\n",
    "\n",
    "ocorrenciasTituloDescricao['PalavrasAntes'] = ocorrenciasTituloDescricao['PalavrasAntes'].str.split('\\n')\n",
    "ocorrenciasTituloDescricao['PalavrasDepois'] = ocorrenciasTituloDescricao['PalavrasDepois'].str.split('\\n')\n",
    "\n",
    "ocorrenciasComents['PalavrasAntes'] = ocorrenciasComents['PalavrasAntes'].str.split('\\n')\n",
    "ocorrenciasComents['PalavrasDepois'] = ocorrenciasComents['PalavrasDepois'].str.split('\\n')\n",
    "\n",
    "ocorrenciasComents = ocorrenciasComents[ocorrenciasComents['Ocorrencias'] > 0]\n",
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao[ocorrenciasTituloDescricao['Ocorrencias'] > 0]\n",
    "\n",
    "ocorrenciasComents = ocorrenciasComents.sort_values(by='Ocorrencias', ascending=False)\n",
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.sort_values(by='Ocorrencias', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Criando uma tabela expansivel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar a tabela com linhas expansíveis e contagem de palavras\n",
    "def criarTabelaExpansivel(df):\n",
    "    displayWidgets = []\n",
    "    \n",
    "    for _, linha in df.iterrows():\n",
    "        # Conta as palavras em 'palavrasAntes' e 'palavrasDepois'\n",
    "        antes_counts = Counter(linha['PalavrasAntes']).most_common()  # Ordena por contagem (decrescente)\n",
    "        depois_counts = Counter(linha['PalavrasDepois']).most_common()  # Ordena por contagem (decrescente)\n",
    "        \n",
    "        # Cria uma linha com os dados principais\n",
    "        linha_widget = widgets.HBox([\n",
    "            widgets.Label(value=str(linha[\"EthicalIssues\"]), layout=widgets.Layout(width=\"120px\")),\n",
    "            widgets.Label(value=str(linha[\"Ocorrencias\"]), layout=widgets.Layout(width=\"60px\")),\n",
    "            widgets.Label(value=\"Clique para expandir\", layout=widgets.Layout(width=\"200px\"))\n",
    "        ])\n",
    "        \n",
    "        # Cria o conteúdo expansível com `palavrasAntes` e `palavrasDepois` e suas contagens\n",
    "        widgetDetalhes = widgets.VBox([\n",
    "            widgets.Label(value=f\"Palavras Antes: {', '.join([f'{word} ({count})' for word, count in antes_counts])}\"),\n",
    "            widgets.Label(value=f\"Palavras Depois: {', '.join([f'{word} ({count})' for word, count in depois_counts])}\")\n",
    "        ])\n",
    "        \n",
    "        # Torna o conteúdo expansível\n",
    "        expansao = widgets.Accordion(children=[widgetDetalhes])\n",
    "        expansao.set_title(0, f\"Detalhes de '{linha['EthicalIssues']}'\")\n",
    "        \n",
    "        # Agrupa a linha principal e o conteúdo expansível\n",
    "        linha_box = widgets.VBox([linha_widget, expansao])\n",
    "        displayWidgets.append(linha_box)\n",
    "    \n",
    "    # Exibe a tabela com todas as linhas e detalhes\n",
    "    display(widgets.VBox(displayWidgets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exibindo os resultados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a tabela expansível\n",
    "criarTabelaExpansivel(ocorrenciasComents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a tabela expansível\n",
    "criarTabelaExpansivel(ocorrenciasTituloDescricao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exportando as Tabelas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando a tabela expansível como um arquivo html\n",
    "\n",
    "def exportar_para_html(df, filepath):\n",
    "    html = \"\"\"<html>\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <style>\n",
    "            table {width: 100%%; border-collapse: collapse;}\n",
    "            th, td {border: 1px solid black; padding: 8px; text-align: left;}\n",
    "            th {background-color: #f2f2f2;}\n",
    "            .detalhes {display: none;}\n",
    "        </style>\n",
    "        <script>\n",
    "            function toggleDetalhes(id) {\n",
    "                var elemento = document.getElementById(id);\n",
    "                elemento.style.display = (elemento.style.display === \"none\") ? \"block\" : \"none\";\n",
    "            }\n",
    "        </script>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h2>Tabela Expansível</h2>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>Ethical Issues</th>\n",
    "                <th>Ocorrências</th>\n",
    "                <th>Detalhes</th>\n",
    "            </tr>\n",
    "    \"\"\"\n",
    "\n",
    "    for i, (_, linha) in enumerate(df.iterrows()):\n",
    "        antes_counts = Counter(linha[\"PalavrasAntes\"]).most_common()\n",
    "        depois_counts = Counter(linha[\"PalavrasDepois\"]).most_common()\n",
    "\n",
    "        detalhes = f\"\"\"<p><strong>Palavras Antes:</strong> {', '.join([f'{word} ({count})' for word, count in antes_counts])}</p>\n",
    "                       <p><strong>Palavras Depois:</strong> {', '.join([f'{word} ({count})' for word, count in depois_counts])}</p>\"\"\"\n",
    "\n",
    "        html += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{linha[\"EthicalIssues\"]}</td>\n",
    "                <td>{linha[\"Ocorrencias\"]}</td>\n",
    "                <td><button onclick=\"toggleDetalhes('detalhes{i}')\">Expandir</button></td>\n",
    "            </tr>\n",
    "            <tr id=\"detalhes{i}\" class=\"detalhes\">\n",
    "                <td colspan=\"3\">{detalhes}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "\n",
    "    html += \"</table></body></html>\"\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exportar_para_html(ocorrenciasComents, \"path_to_html\")\n",
    "#exportar_para_html(ocorrenciasTituloDescricao, \"path_to_html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualização dos Dados:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataframes finais:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocorrenciasComents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocorrenciasTituloDescricao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualizações:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gráfico de Barras Vertical (Comentários)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 10))\n",
    "sns.barplot(x=\"Ocorrencias\", y=\"EthicalIssues\", data=ocorrenciasComents.sort_values(\"Ocorrencias\", ascending=False), palette=\"viridis\")\n",
    "plt.xlabel(\"Ocorrências\")\n",
    "plt.ylabel(\"Temas Éticos\")\n",
    "plt.title(\"Frequência de Ocorrências de Temas Éticos\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gráfico de Barras Vertical (Infos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 10))\n",
    "sns.barplot(x=\"Ocorrencias\", y=\"EthicalIssues\", data=ocorrenciasTituloDescricao.sort_values(\"Ocorrencias\", ascending=False), palette=\"viridis\")\n",
    "plt.xlabel(\"Ocorrências\")\n",
    "plt.ylabel(\"Temas Éticos\")\n",
    "plt.title(\"Frequência de Ocorrências de Temas Éticos\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Palavras que Mais Ocorreram Antes e Depois (Comentários):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função corrigida para contar palavras\n",
    "def getTopPalavra(lista_palavras, n=3):\n",
    "    # Achatamos TODOS os níveis de listas aninhadas\n",
    "    palavras = []\n",
    "    for sublist in lista_palavras:\n",
    "        if isinstance(sublist, list):\n",
    "            palavras.extend(sublist)\n",
    "        else:\n",
    "            palavras.append(sublist)\n",
    "    return Counter(palavras).most_common(n)\n",
    "\n",
    "\n",
    "ocorrenciasComents['Antes'] = ocorrenciasComents['PalavrasAntes'].apply(lambda x: getTopPalavra(x, 1))\n",
    "ocorrenciasComents['Depois'] = ocorrenciasComents['PalavrasDepois'].apply(lambda x: getTopPalavra(x, 1))\n",
    "\n",
    "# DataFrame de resultados\n",
    "result_df_coment = pd.DataFrame({\n",
    "    'Problema Ético': ocorrenciasComents['EthicalIssues'],\n",
    "    'Palavra Antes': ocorrenciasComents['Antes'].apply(lambda x: f\"{x[0][0]} ({x[0][1]})\" if x else '-'),\n",
    "    'Palavra Depois': ocorrenciasComents['Depois'].apply(lambda x: f\"{x[0][0]} ({x[0][1]})\" if x else '-'),\n",
    "    'Freq Antes': ocorrenciasComents['Antes'].apply(lambda x: f\"{x[0][1]}\" if x else '-'),\n",
    "    'Freq Depois': ocorrenciasComents['Depois'].apply(lambda x: f\"{x[0][1]}\" if x else '-')\n",
    "})\n",
    "\n",
    "result_df_coment[\"Freq Antes\"] = pd.to_numeric(result_df_coment[\"Freq Antes\"], errors=\"coerce\")\n",
    "result_df_coment[\"Freq Depois\"] = pd.to_numeric(result_df_coment[\"Freq Depois\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# Estilo da tabela\n",
    "def style_table(styler):\n",
    "    styler.set_properties(**{\n",
    "        'text-align': 'left',\n",
    "        'padding': '6px',\n",
    "        'font-family': 'Arial',\n",
    "        'border': '1px solid #ddd'\n",
    "    })\n",
    "    styler.set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('background-color', '#f8f9fa'), \n",
    "                 ('font-weight', 'bold'),\n",
    "                 ('color', '#333')]\n",
    "    }])\n",
    "    return styler\n",
    "\n",
    "# Exibição\n",
    "display(HTML(\n",
    "    result_df_coment[[\"Problema Ético\", \"Palavra Antes\", \"Palavra Depois\"]].style\n",
    "    .pipe(style_table)\n",
    "    .set_caption(\"<b>Palavras mais frequentes associadas a cada problema ético</b>\")\n",
    "    .to_html()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Palavras que Mais Ocorreram Antes e Depois (Infos):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função corrigida para contar palavras\n",
    "def getTopPalavra(lista_palavras, n=3):\n",
    "    # Achatamos TODOS os níveis de listas aninhadas\n",
    "    palavras = []\n",
    "    for sublist in lista_palavras:\n",
    "        if isinstance(sublist, list):\n",
    "            palavras.extend(sublist)\n",
    "        else:\n",
    "            palavras.append(sublist)\n",
    "    return Counter(palavras).most_common(n)\n",
    "\n",
    "\n",
    "ocorrenciasTituloDescricao['Antes'] = ocorrenciasTituloDescricao['PalavrasAntes'].apply(lambda x: getTopPalavra(x, 1))\n",
    "ocorrenciasTituloDescricao['Depois'] = ocorrenciasTituloDescricao['PalavrasDepois'].apply(lambda x: getTopPalavra(x, 1))\n",
    "\n",
    "# DataFrame de resultados\n",
    "result_df_info = pd.DataFrame({\n",
    "    'Problema Ético': ocorrenciasTituloDescricao['EthicalIssues'],\n",
    "    'Palavra Antes': ocorrenciasTituloDescricao['Antes'].apply(lambda x: f\"{x[0][0]} ({x[0][1]})\" if x else '-'),\n",
    "    'Palavra Depois': ocorrenciasTituloDescricao['Depois'].apply(lambda x: f\"{x[0][0]} ({x[0][1]})\" if x else '-'),\n",
    "    'Freq Antes': ocorrenciasTituloDescricao['Antes'].apply(lambda x: f\"{x[0][1]}\" if x else '-'),\n",
    "    'Freq Depois': ocorrenciasTituloDescricao['Depois'].apply(lambda x: f\"{x[0][1]}\" if x else '-')\n",
    "})\n",
    "\n",
    "result_df_info[\"Freq Antes\"] = pd.to_numeric(result_df_info[\"Freq Antes\"], errors=\"coerce\")\n",
    "result_df_info[\"Freq Depois\"] = pd.to_numeric(result_df_info[\"Freq Depois\"], errors=\"coerce\")\n",
    "\n",
    "# Estilo da tabela\n",
    "def style_table(styler):\n",
    "    styler.set_properties(**{\n",
    "        'text-align': 'left',\n",
    "        'padding': '6px',\n",
    "        'font-family': 'Arial',\n",
    "        'border': '1px solid #ddd'\n",
    "    })\n",
    "    styler.set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('background-color', '#f8f9fa'), \n",
    "                 ('font-weight', 'bold'),\n",
    "                 ('color', '#333')]\n",
    "    }])\n",
    "    return styler\n",
    "\n",
    "# Exibição\n",
    "display(HTML(\n",
    "    result_df_info[[\"Problema Ético\", \"Palavra Antes\", \"Palavra Depois\"]].style\n",
    "    .pipe(style_table)\n",
    "    .set_caption(\"<b>Palavras mais frequentes associadas a cada problema ético</b>\")\n",
    "    .to_html()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela com cores Info\n",
    "styled_df = result_df_info.style.set_properties(subset=[\"Palavra Antes\"], **{'color': 'blue', 'font-weight': 'bold'}) \\\n",
    "                    .set_properties(subset=[\"Palavra Depois\"], **{'color': 'red', 'font-weight': 'bold'})\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela com cores Coments\n",
    "styled_df = result_df_coment.style.set_properties(subset=[\"Palavra Antes\"], **{'color': 'blue', 'font-weight': 'bold'}) \\\n",
    "                    .set_properties(subset=[\"Palavra Depois\"], **{'color': 'red', 'font-weight': 'bold'})\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras horizontais\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "df = result_df_coment.head(5)\n",
    "y = np.arange(len(df))\n",
    "bar_width = 0.2\n",
    "\n",
    "# Barras\n",
    "ax.barh(y - bar_width/2, df[\"Freq Antes\"], height=bar_width, color='skyblue', label='Antes')\n",
    "ax.barh(y + bar_width/2, df[\"Freq Depois\"], height=bar_width, color='salmon', label='Depois')\n",
    "\n",
    "# Rótulos com palavras\n",
    "for i in range(len(df)):\n",
    "    ax.text(df[\"Freq Antes\"].iloc[i] + 1, y[i] - bar_width/2, df[\"Palavra Antes\"].iloc[i], va='center', color='blue')\n",
    "    ax.text(df[\"Freq Depois\"].iloc[i] + 1, y[i] + bar_width/2, df[\"Palavra Depois\"].iloc[i], va='center', color='red')\n",
    "\n",
    "# Estilo\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(df[\"Problema Ético\"])\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Frequência\")\n",
    "ax.set_title(\"Palavras Antes e Depois dos Problemas Éticos\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras horizontais\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "df = result_df_info.head(10)\n",
    "y = np.arange(len(df))\n",
    "bar_width = 0.2\n",
    "\n",
    "# Barras\n",
    "ax.barh(y - bar_width/2, df[\"Freq Antes\"], height=bar_width, color='skyblue', label='Antes')\n",
    "ax.barh(y + bar_width/2, df[\"Freq Depois\"], height=bar_width, color='salmon', label='Depois')\n",
    "\n",
    "# Rótulos com palavras\n",
    "for i in range(len(df)):\n",
    "    ax.text(df[\"Freq Antes\"].iloc[i] + 1, y[i] - bar_width/2, df[\"Palavra Antes\"].iloc[i], va='center', color='blue')\n",
    "    ax.text(df[\"Freq Depois\"].iloc[i] + 1, y[i] + bar_width/2, df[\"Palavra Depois\"].iloc[i], va='center', color='red')\n",
    "\n",
    "# Estilo\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(df[\"Problema Ético\"])\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Frequência\")\n",
    "ax.set_title(\"Palavras Antes e Depois dos Problemas Éticos\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Dicionários com as palavras e frequências\n",
    "freq_antes = dict(zip(result_df_coment[\"Palavra Antes\"], result_df_coment[\"Freq Antes\"]))\n",
    "freq_depois = dict(zip(result_df_coment[\"Palavra Depois\"], result_df_coment[\"Freq Depois\"]))\n",
    "\n",
    "# Gerar nuvens\n",
    "wordcloud_antes = WordCloud(width=400, height=300, background_color='white', colormap='Blues').generate_from_frequencies(freq_antes)\n",
    "wordcloud_depois = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate_from_frequencies(freq_depois)\n",
    "\n",
    "# Mostrar lado a lado\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axs[0].imshow(wordcloud_antes, interpolation='bilinear')\n",
    "axs[0].set_title(\"Palavras Antes\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(wordcloud_depois, interpolation='bilinear')\n",
    "axs[1].set_title(\"Palavras Depois\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Dicionários com as palavras e frequências\n",
    "freq_antes = dict(zip(result_df_info[\"Palavra Antes\"], result_df_info[\"Freq Antes\"]))\n",
    "freq_depois = dict(zip(result_df_info[\"Palavra Depois\"], result_df_info[\"Freq Depois\"]))\n",
    "\n",
    "# Gerar nuvens\n",
    "wordcloud_antes = WordCloud(width=400, height=300, background_color='white', colormap='Blues').generate_from_frequencies(freq_antes)\n",
    "wordcloud_depois = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate_from_frequencies(freq_depois)\n",
    "\n",
    "# Mostrar lado a lado\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axs[0].imshow(wordcloud_antes, interpolation='bilinear')\n",
    "axs[0].set_title(\"Palavras Antes\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(wordcloud_depois, interpolation='bilinear')\n",
    "axs[1].set_title(\"Palavras Depois\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
