{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Procura de Problemas Éticos em Issues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fazendo a leitura dos dados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = pd.read_csv(\"out/daggerfall-unity-issues-3.csv\")\n",
    "comentarios = pd.read_csv(\"out/daggerfall-unity-comentarios-3.csv\")\n",
    "\n",
    "# Concatenando o Titulo e a Descrição das issues\n",
    "issues['Info'] = issues['TituloIssue'] + issues['DescricaoIssue']\n",
    "\n",
    "# Convertendo todos os tipos para String\n",
    "issues['Info'] = issues['Info'].astype(str)\n",
    "comentarios['Comentario'] = comentarios['Comentario'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenizando os Comentarios, Titulo e Descrição das Issues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/zoega/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo as StopWords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "def removerStopWords(palavras):\n",
    "    return [palavra for palavra in palavras if palavra not in stopWords and palavra.isalpha()]\n",
    "\n",
    "# Criando um tokenizer que considera expressões\n",
    "expressoes = {'Data Governance', 'Data Protection','Informed Consent', 'Lack of Data', 'User Data Collection' 'Business Ethics','Conflict of Interest',\n",
    "            'Human Agency', 'Intellectual Property','Regulatory Approaches', 'Self-Conception','Professional Ethics', 'Work Ethics','Common Goods','Individual Differences',\n",
    "            'Non-Discrimination', 'Non-Maleficence','Prevention of Harm', 'Quality of Life', 'Respect for Human Autonomy', 'Retention and Addiction', 'Social Justice',\n",
    "            'Speech Issues', 'Technical Robustness','Computer Abuse', 'Malicious Use'}\n",
    "\n",
    "expressaoRegular = r'\\b(?:' + '|'.join(expressoes) + r')\\b|\\w+'\n",
    "tokenizer = RegexpTokenizer(expressaoRegular)\n",
    "\n",
    "\n",
    "# Tokenize dos comentarios das issues\n",
    "comentariosToK = []\n",
    "for i in range (comentarios['Comentario'].size):\n",
    "    comentariosToK.append(removerStopWords(tokenizer.tokenize(comentarios.loc[i]['Comentario'])))\n",
    "    removerStopWords(comentariosToK[i])\n",
    "\n",
    "# Tokenize do campo Info\n",
    "tituloDescricaoToK = []\n",
    "for k in range(issues['Info'].size):\n",
    "    tituloDescricaoToK.append(removerStopWords(tokenizer.tokenize(issues.loc[k]['Info'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Contando a ocorrência de problemas éticos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ocorrencias</th>\n",
       "      <th>PalavrasAntes</th>\n",
       "      <th>PalavrasDepois</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EthicalIssues</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bias</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Governance</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Protection</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Encryption</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Informed Consent</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traceability</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transparency</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usability</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer Abuse</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malicious Use</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Ocorrencias PalavrasAntes PalavrasDepois\n",
       "EthicalIssues                                             \n",
       "Bias                        0                             \n",
       "Data Governance             0                             \n",
       "Data Protection             0                             \n",
       "Encryption                  0                             \n",
       "Informed Consent            0                             \n",
       "...                       ...           ...            ...\n",
       "Traceability                0                             \n",
       "Transparency                0                             \n",
       "Usability                   0                             \n",
       "Computer Abuse              0                             \n",
       "Malicious Use               0                             \n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo os EthicalIssues\n",
    "EthicalIssues = ['Bias', 'Data Governance', 'Data Protection', 'Encryption', 'Informed Consent', 'Lack of Data', 'Monetization', 'Openness', 'Privacy', 'User Data Collection'\n",
    "            'Authorship', 'Autonomy', 'Beneficence', 'Business Ethics', 'Commerce', 'Compliance', 'Confidentiality', 'Conflict of Interest', 'Context', 'Dependability',\n",
    "            'Fairness', 'Human Agency', 'Intellectual Property', 'Oversight', 'Regulatory Approaches', 'Responsibility', 'Trust', 'Trustworthiness', 'Axiology', 'Freedom',\n",
    "            'Self-Conception', 'Solidarity', 'Utility', 'Care', 'Competence', 'Professional Ethics', 'Work Ethics', 'Access', 'Accessibility', 'Common Goods', 'Dignity',\n",
    "            'Diversity', 'Equality', 'Equity', 'Humanity', 'Inclusiveness', 'Individual Differences', 'Inequality', 'Justice', 'Non-Discrimination', 'Non-Maleficence',\n",
    "            'Participation', 'Plurality', 'Prevention of Harm', 'Quality of Life', 'Respect for Human Autonomy', 'Retention and Addiction', 'Social Justice', 'Sustainability',\n",
    "            'Unemployment', 'Welfare', 'Accountability', 'Accuracy', 'Anonymity', 'Comprehensibility', 'Consistency', 'Contestability', 'Explainability', 'Explicability',\n",
    "            'Integrity', 'Interpretability', 'Liability', 'Reliability', 'Safety', 'Security', 'Speech Issues', 'Technical Robustness', 'Traceability', 'Transparency',\n",
    "            'Usability', 'Computer Abuse', 'Malicious Use']\n",
    "\n",
    "# Criando o DataFrame que guardará as ocorrências dos comentários\n",
    "ocorrenciasComents = pd.DataFrame()\n",
    "linhaInicial = 0 * len(EthicalIssues)\n",
    "palavrasAntes = \"\" * len(EthicalIssues)\n",
    "palavrasDepois = \"\" * len(EthicalIssues)\n",
    "\n",
    "ocorrenciasComents['EthicalIssues'] = EthicalIssues\n",
    "ocorrenciasComents['Ocorrencias'] = linhaInicial\n",
    "ocorrenciasComents[\"PalavrasAntes\"] = palavrasAntes\n",
    "ocorrenciasComents[\"PalavrasDepois\"] = palavrasDepois\n",
    "ocorrenciasComents = ocorrenciasComents.set_index('EthicalIssues')\n",
    "ocorrenciasComents\n",
    "\n",
    "# Criando o DataFrame que guardará as ocorrências do título e descrição\n",
    "ocorrenciasTituloDescricao = pd.DataFrame()\n",
    "linhaInicial = 0 * len(EthicalIssues)\n",
    "palavrasAntes = \"\" * len(EthicalIssues)\n",
    "palavrasDepois = \"\" * len(EthicalIssues)\n",
    "\n",
    "ocorrenciasTituloDescricao['EthicalIssues'] = EthicalIssues\n",
    "ocorrenciasTituloDescricao['Ocorrencias'] = linhaInicial\n",
    "ocorrenciasTituloDescricao[\"PalavrasAntes\"] = palavrasAntes\n",
    "ocorrenciasTituloDescricao[\"PalavrasDepois\"] = palavrasDepois\n",
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.set_index('EthicalIssues')\n",
    "ocorrenciasTituloDescricao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(comentariosToK)):\n",
    "    for j in range(len(comentariosToK[i])):\n",
    "        \n",
    "        if(comentariosToK[i][j] in EthicalIssues):\n",
    "            \n",
    "            ocorrenciasComents.loc[comentariosToK[i][j], 'Ocorrencias'] += 1\n",
    "            \n",
    "            if((j - 1) >= 0):\n",
    "                if(ocorrenciasComents.loc[comentariosToK[i][j],'PalavrasAntes'] == ''):\n",
    "                    ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasAntes'] = comentariosToK[i][j - 1]\n",
    "                else:\n",
    "                    ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasAntes'] += ('\\n' + comentariosToK[i][j - 1])\n",
    "            if((j + 1) <= (len(comentariosToK[i]) - 1)):\n",
    "                if(ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasDepois'] == ''):\n",
    "                    ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasDepois'] = comentariosToK[i][j + 1]\n",
    "                else:\n",
    "                    ocorrenciasComents.loc[comentariosToK[i][j], 'PalavrasDepois'] += ('\\n' + comentariosToK[i][j + 1])\n",
    "\n",
    "\n",
    "for i in range(len(tituloDescricaoToK)):\n",
    "    for j in range(len(tituloDescricaoToK[i])):\n",
    "        \n",
    "        if(tituloDescricaoToK[i][j] in EthicalIssues):\n",
    "            \n",
    "            ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'Ocorrencias'] += 1\n",
    "            \n",
    "            if((j - 1) >= 0):\n",
    "                if(ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j],'PalavrasAntes'] == ''):\n",
    "                    ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasAntes'] = tituloDescricaoToK[i][j - 1]\n",
    "                else:\n",
    "                    ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasAntes'] += ('\\n' + tituloDescricaoToK[i][j - 1])\n",
    "            if((j + 1) <= (len(tituloDescricaoToK[i]) - 1)):\n",
    "                if(ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasDepois'] == ''):\n",
    "                    ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasDepois'] = tituloDescricaoToK[i][j + 1]\n",
    "                else:\n",
    "                    ocorrenciasTituloDescricao.loc[tituloDescricaoToK[i][j], 'PalavrasDepois'] += ('\\n' + tituloDescricaoToK[i][j + 1])\n",
    "\n",
    "# Isso aqui funcionou, porém ainda não consegui resolver os problemas de links e imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exportando os resultados para um csv:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocorrenciasTituloDescricao = ocorrenciasTituloDescricao.reset_index()\n",
    "ocorrenciasComents = ocorrenciasComents.reset_index()\n",
    "\n",
    "caminhoPasta = 'out'\n",
    "nomeArquivo = 'Comentarios.csv'\n",
    "caminhoArquivo = os.path.join(caminhoPasta, nomeArquivo)\n",
    "\n",
    "if not os.path.exists(caminhoPasta):\n",
    "    os.makedirs(caminhoPasta)\n",
    "\n",
    "ocorrenciasComents.to_csv(caminhoArquivo, sep=',', index=False, header=True, na_rep='N/A', encoding='utf-8')\n",
    "\n",
    "caminhoPasta = 'out'\n",
    "nomeArquivo = 'TituloDescricao.csv'\n",
    "caminhoArquivo = os.path.join(caminhoPasta, nomeArquivo)\n",
    "\n",
    "if not os.path.exists(caminhoPasta):\n",
    "    os.makedirs(caminhoPasta)\n",
    "\n",
    "ocorrenciasTituloDescricao.to_csv(caminhoArquivo, sep=',', index=False, header=True, na_rep='N/A', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
